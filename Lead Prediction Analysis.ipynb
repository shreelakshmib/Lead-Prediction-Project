{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sbhatt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json \n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remarks</th>\n",
       "      <th>leadName</th>\n",
       "      <th>gender</th>\n",
       "      <th>city</th>\n",
       "      <th>reference</th>\n",
       "      <th>academicYear</th>\n",
       "      <th>englishYear</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tomarrow coming</td>\n",
       "      <td>Adithya</td>\n",
       "      <td>M</td>\n",
       "      <td>ERNAKULAM</td>\n",
       "      <td>Online</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>2017</td>\n",
       "      <td>MBA   Jain University,MS RAMAIAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today coming</td>\n",
       "      <td>Adithya</td>\n",
       "      <td>M</td>\n",
       "      <td>ERNAKULAM</td>\n",
       "      <td>Online</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>2017</td>\n",
       "      <td>MBA   Jain University,MS RAMAIAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>today coming</td>\n",
       "      <td>Adithya</td>\n",
       "      <td>M</td>\n",
       "      <td>ERNAKULAM</td>\n",
       "      <td>Online</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>2017</td>\n",
       "      <td>MBA   Jain University,MS RAMAIAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>just taking decision</td>\n",
       "      <td>Adithya</td>\n",
       "      <td>M</td>\n",
       "      <td>ERNAKULAM</td>\n",
       "      <td>Online</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>2017</td>\n",
       "      <td>MBA   Jain University,MS RAMAIAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>formal talk</td>\n",
       "      <td>Adithya</td>\n",
       "      <td>M</td>\n",
       "      <td>ERNAKULAM</td>\n",
       "      <td>Online</td>\n",
       "      <td>2017-18</td>\n",
       "      <td>2017</td>\n",
       "      <td>MBA   Jain University,MS RAMAIAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112</th>\n",
       "      <td>XTH 95% XII EXPECTING 95% TRANSFERRED RS 3540 ...</td>\n",
       "      <td>Darshan Suresh Shetty</td>\n",
       "      <td>F</td>\n",
       "      <td>UK</td>\n",
       "      <td>Galaxy portal set 8 2020</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29113</th>\n",
       "      <td>transferred rs 3540 for admission guidance on ...</td>\n",
       "      <td>Darshan Suresh Shetty</td>\n",
       "      <td>F</td>\n",
       "      <td>UK</td>\n",
       "      <td>Galaxy portal set 8 2020</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29114</th>\n",
       "      <td>XTH 74%/XII-72% BBA LAST YEAR COMPLETED/LOOKIN...</td>\n",
       "      <td>MUHAMMED SAMAN V SIRAJ</td>\n",
       "      <td>M</td>\n",
       "      <td>MUSCAT</td>\n",
       "      <td>Students Reference</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29115</th>\n",
       "      <td>WILL FINALISE THE COLLEGE  AND CALL BACK ON TO...</td>\n",
       "      <td>MUHAMMED SAMAN V SIRAJ</td>\n",
       "      <td>M</td>\n",
       "      <td>MUSCAT</td>\n",
       "      <td>Students Reference</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29116</th>\n",
       "      <td>INTERESTED FOR IFIM ADMISSION/WILL DISCUSS WIT...</td>\n",
       "      <td>MUHAMMED SAMAN V SIRAJ</td>\n",
       "      <td>M</td>\n",
       "      <td>MUSCAT</td>\n",
       "      <td>Students Reference</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29117 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 remarks  \\\n",
       "0                                        tomarrow coming   \n",
       "1                                           Today coming   \n",
       "2                                           today coming   \n",
       "3                                   just taking decision   \n",
       "4                                            formal talk   \n",
       "...                                                  ...   \n",
       "29112  XTH 95% XII EXPECTING 95% TRANSFERRED RS 3540 ...   \n",
       "29113  transferred rs 3540 for admission guidance on ...   \n",
       "29114  XTH 74%/XII-72% BBA LAST YEAR COMPLETED/LOOKIN...   \n",
       "29115  WILL FINALISE THE COLLEGE  AND CALL BACK ON TO...   \n",
       "29116  INTERESTED FOR IFIM ADMISSION/WILL DISCUSS WIT...   \n",
       "\n",
       "                     leadName gender       city                 reference  \\\n",
       "0                     Adithya      M  ERNAKULAM                    Online   \n",
       "1                     Adithya      M  ERNAKULAM                    Online   \n",
       "2                     Adithya      M  ERNAKULAM                    Online   \n",
       "3                     Adithya      M  ERNAKULAM                    Online   \n",
       "4                     Adithya      M  ERNAKULAM                    Online   \n",
       "...                       ...    ...        ...                       ...   \n",
       "29112   Darshan Suresh Shetty      F         UK  Galaxy portal set 8 2020   \n",
       "29113   Darshan Suresh Shetty      F         UK  Galaxy portal set 8 2020   \n",
       "29114  MUHAMMED SAMAN V SIRAJ      M     MUSCAT        Students Reference   \n",
       "29115  MUHAMMED SAMAN V SIRAJ      M     MUSCAT        Students Reference   \n",
       "29116  MUHAMMED SAMAN V SIRAJ      M     MUSCAT        Students Reference   \n",
       "\n",
       "      academicYear englishYear                             notes  \n",
       "0          2017-18        2017  MBA   Jain University,MS RAMAIAH  \n",
       "1          2017-18        2017  MBA   Jain University,MS RAMAIAH  \n",
       "2          2017-18        2017  MBA   Jain University,MS RAMAIAH  \n",
       "3          2017-18        2017  MBA   Jain University,MS RAMAIAH  \n",
       "4          2017-18        2017  MBA   Jain University,MS RAMAIAH  \n",
       "...            ...         ...                               ...  \n",
       "29112      2020-21        2020                               NaN  \n",
       "29113      2020-21        2020                               NaN  \n",
       "29114      2020-21        2020                               NaN  \n",
       "29115      2020-21        2020                               NaN  \n",
       "29116      2020-21        2020                               NaN  \n",
       "\n",
       "[29117 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the input file to train the model which has around 1600 accepted leads and 1600 rejected leads \n",
    "registeredLeads = \"registered_leads.json\"\n",
    "exportPath = \"testing_registered_leads.json\"\n",
    "\n",
    "\n",
    "with open(registeredLeads,'r',encoding='utf-8') as f1:\n",
    "    data_fromFile = f1.read()\n",
    "    data_fromFile = '[' + data_fromFile.replace('\\n', ',\\n') + ']'\n",
    "\n",
    "with open(exportPath,'w',encoding='utf-8') as f2:\n",
    "    f2.write(data_fromFile)\n",
    "    \n",
    "with open(exportPath,'r',encoding='utf-8') as f3:\n",
    "    jsonObject = json.load(f3)\n",
    "    registeredLeadDf = pd.DataFrame(jsonObject, columns=['leadName','gender','city','reference','notes','academicYear','englishYear'])\n",
    "    normalize = pd.json_normalize(jsonObject,record_path = 'followUpLog',meta=['leadName','dob','gender','city','reference','academicYear','englishYear','notes'],errors = 'ignore')\n",
    "                \n",
    "    normalizedRegisteredLeadDf = normalize.drop(columns = ['contactNumberMail','nextFollowUp','dob','user','contactLogResponse','contactTime.$numberInt','nextFollowUp.$numberInt',\n",
    "                                    'successful.$numberInt','nextFollowUp.$numberLong','successful','callDuration'])\n",
    "    \n",
    "normalizedRegisteredLeadDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remarks</th>\n",
       "      <th>leadName</th>\n",
       "      <th>gender</th>\n",
       "      <th>city</th>\n",
       "      <th>reference</th>\n",
       "      <th>academicYear</th>\n",
       "      <th>englishYear</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29117</td>\n",
       "      <td>29117</td>\n",
       "      <td>29117</td>\n",
       "      <td>29080</td>\n",
       "      <td>29117</td>\n",
       "      <td>29117</td>\n",
       "      <td>29117</td>\n",
       "      <td>28103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>17934</td>\n",
       "      <td>1597</td>\n",
       "      <td>4</td>\n",
       "      <td>738</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Not Attending</td>\n",
       "      <td>Md Mobashirul Islam</td>\n",
       "      <td>M</td>\n",
       "      <td>BANGALORE</td>\n",
       "      <td>SNEHA</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>2019</td>\n",
       "      <td>MBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1424</td>\n",
       "      <td>89</td>\n",
       "      <td>22438</td>\n",
       "      <td>1123</td>\n",
       "      <td>4113</td>\n",
       "      <td>11709</td>\n",
       "      <td>15578</td>\n",
       "      <td>3712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              remarks             leadName gender       city reference  \\\n",
       "count           29117                29117  29117      29080     29117   \n",
       "unique          17934                 1597      4        738        58   \n",
       "top     Not Attending  Md Mobashirul Islam      M  BANGALORE     SNEHA   \n",
       "freq             1424                   89  22438       1123      4113   \n",
       "\n",
       "       academicYear englishYear  notes  \n",
       "count         29117       29117  28103  \n",
       "unique           15           5    648  \n",
       "top         2019-20        2019    MBA  \n",
       "freq          11709       15578   3712  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizedRegisteredLeadDf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29117 entries, 0 to 29116\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   remarks       29117 non-null  object\n",
      " 1   leadName      29117 non-null  object\n",
      " 2   gender        29117 non-null  object\n",
      " 3   city          29080 non-null  object\n",
      " 4   reference     29117 non-null  object\n",
      " 5   academicYear  29117 non-null  object\n",
      " 6   englishYear   29117 non-null  object\n",
      " 7   notes         28103 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "normalizedRegisteredLeadDf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-20         11709\n",
       "2018-19          9035\n",
       "2020-21          4229\n",
       "2017-18          1392\n",
       "2016-17           806\n",
       "2021-22           516\n",
       "2019-2021         500\n",
       "2019-2020         345\n",
       "2019              334\n",
       "2020 - 2021        91\n",
       "2018-2019          73\n",
       "2020-2021          42\n",
       "counselling        20\n",
       "2017-2018          14\n",
       "2020-2022          11\n",
       "Name: academicYear, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizedRegisteredLeadDf['academicYear'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019    15578\n",
       "2018     5979\n",
       "2020     4894\n",
       "2017     2073\n",
       "2021      593\n",
       "Name: englishYear, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizedRegisteredLeadDf['englishYear'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     We can see lot of duplicate year mentioned. We can modify them and add them to one category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    22438\n",
       "F     6466\n",
       "       167\n",
       "m       46\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizedRegisteredLeadDf['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    167 rows of data has null string. We can either imputate or drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BANGALORE          1123\n",
       "Bangalore           999\n",
       "Bangalore           769\n",
       "KOTTAYAM            620\n",
       "bangalore           553\n",
       "                   ... \n",
       "Bhatkal               1\n",
       "PALA                  1\n",
       "Orissa                1\n",
       "jammu & kashmir       1\n",
       "s                     1\n",
       "Name: city, Length: 738, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizedRegisteredLeadDf['city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBA                                            3712\n",
       "MBBS                                           3017\n",
       "                                               1818\n",
       "BBA                                            1140\n",
       "BAMS                                            595\n",
       "                                               ... \n",
       "MBA   jain                                        2\n",
       "b.e cs   t.john                                   1\n",
       "mba finance   cms jain                            1\n",
       "BPT   rajarajeswari medical medical college       1\n",
       "BTECH in CS                                       1\n",
       "Name: notes, Length: 648, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizedRegisteredLeadDf['notes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNEHA                           4113\n",
       "Website General Enquiry         3995\n",
       "WebsiteChat                     3921\n",
       "Incoming call                   3656\n",
       "Online                          2720\n",
       "Students Reference              2400\n",
       "Galaxy portal set 7             1172\n",
       "Galaxy Portal 2019 Set 1        1058\n",
       "Gladiator                        613\n",
       "Galaxy portal set 1              495\n",
       "Galaxy portal 2019 set 2         409\n",
       "KEAM DATA                        402\n",
       "WhatsApp Chat                    380\n",
       "Mission 35                       316\n",
       "Galaxy portal set 8 2020         296\n",
       "Galaxy portal set 3              276\n",
       "Hareesh                          269\n",
       "Gautham Associates               218\n",
       "Galaxy portal set 3 2019         201\n",
       "KEA 2018                         183\n",
       "Direct WalkIn                    153\n",
       "Galaxy portal set 2              119\n",
       "college batch                    114\n",
       "galaxy portal set 5              114\n",
       "GM WEBSITE ENQUIRY               109\n",
       "No Reference                     109\n",
       "MAT DECEMBER 2018                 95\n",
       "Galaxy Portal                     82\n",
       "vyasa leads                       82\n",
       "ISE KOTTAYAM                      81\n",
       "ISE TRIVANDRUM                    80\n",
       "COMEDK 2018                       79\n",
       "BHUDHA                            78\n",
       "MAT FEBRUARY 2018                 78\n",
       "isc kottayam 2018                 73\n",
       "Rajesh Minerva                    67\n",
       "Galaxy portal 2019 set 4          60\n",
       "university data                   53\n",
       "College Batch Lead Reference      52\n",
       "NH                                40\n",
       "MD LEADS                          38\n",
       "MICROTECH KOCHI                   35\n",
       "bangalore data                    29\n",
       "Facebook leads                    25\n",
       "AP DATA                           25\n",
       "Incoming Call                     24\n",
       "AJ ONLINE                         18\n",
       "GALAXY                            17\n",
       "isc trivandrum 2018               14\n",
       "EAMCET TELENGALA                  13\n",
       "RAFI                              13\n",
       "KASHMIR LEADS AKL                 12\n",
       "ISE CALICUT                       10\n",
       "Life planner                      10\n",
       "ISE KANNUR                         8\n",
       "sunny kolkatta                     8\n",
       "younus                             4\n",
       "AICA                               3\n",
       "Name: reference, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizedRegisteredLeadDf['reference'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Data\n",
    "exportPath = \"testing_junk_leads.json\"\n",
    "theWholeDataDf = \"junk_leads.json\"\n",
    "\n",
    "\n",
    "with open(theWholeDataDf,'r',encoding='utf-8') as f1:\n",
    "    data_fromFile = f1.read()\n",
    "    data_fromFile = '[' + data_fromFile.replace('\\n', ',\\n') + ']'\n",
    "\n",
    "with open(exportPath,'w',encoding='utf-8') as f2:\n",
    "    f2.write(data_fromFile)\n",
    "    \n",
    "with open(exportPath,'r',encoding='utf-8') as f3:\n",
    "    jsonObject = json.load(f3)\n",
    "    unregisteredLeadDf = pd.DataFrame(jsonObject, columns=['leadName','gender','city','academicYear','englishYear'])\n",
    "    normalize = pd.json_normalize(jsonObject,record_path = 'followUpLog',meta=['leadName','dob','gender','city','reference','notes','academicYear','englishYear'],errors = 'ignore')\n",
    "                \n",
    "    normalizedUnRegisteredLeadDf = normalize.drop(columns = ['contactNumberMail','nextFollowUp','dob','user','contactLogResponse','contactTime.$numberInt','nextFollowUp.$numberInt',\n",
    "                                    'successful.$numberInt','successful','callDuration'])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the entire data to lower case:\n",
    "\n",
    "normalizedRegisteredLeadDf = normalizedRegisteredLeadDf.apply(lambda x: x.astype(str).str.lower())\n",
    "normalizedUnRegisteredLeadDf = normalizedUnRegisteredLeadDf.apply(lambda x: x.astype(str).str.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning : \n",
    "\n",
    "#1. Acadmeic Years are arranged properly.\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'2017-18' : '2017'},regex=True)\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'2016-17' : '2016'},regex=True)\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'2020-21' : '2020'},regex=True)\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'2018-19' : '2018'},regex=True)\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'2017-2018' : '2017'},regex=True)\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'2018-2019' : '2018'},regex=True)\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'2019-2020' : '2019'},regex=True)\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'2019-20' : '2019'},regex=True)\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'2021-22' : '2021'},regex=True)\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'counselling' : '2019'},regex=True)\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'2019-2021' : '2019'},regex=True)\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'2020-2022' : '2020'},regex=True)\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'2020-2021' : '2020'},regex=True)\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'2020 - 2021' : '2020'},regex=True)\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'2019 ' : '2019'},regex=True)\n",
    "normalizedRegisteredLeadDf['academicYear'] = normalizedRegisteredLeadDf['academicYear'].replace(to_replace = {r'201921' : '2019'},regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizedUnRegisteredLeadDf['academicYear'] = normalizedUnRegisteredLeadDf['academicYear'].replace(to_replace = {r'2019-20' : '2019'},regex=True)\n",
    "normalizedUnRegisteredLeadDf['academicYear'] = normalizedUnRegisteredLeadDf['academicYear'].replace(to_replace = {r'2018-19' : '2018'},regex=True)\n",
    "normalizedUnRegisteredLeadDf['academicYear'] = normalizedUnRegisteredLeadDf['academicYear'].replace(to_replace = {r'2016-17' : '2016'},regex=True)\n",
    "normalizedUnRegisteredLeadDf['academicYear'] = normalizedUnRegisteredLeadDf['academicYear'].replace(to_replace = {r'2020-21' : '2020'},regex=True)\n",
    "normalizedUnRegisteredLeadDf['academicYear'] = normalizedUnRegisteredLeadDf['academicYear'].replace(to_replace = {r'2020-22' : '2020'},regex=True)\n",
    "normalizedUnRegisteredLeadDf['academicYear'] = normalizedUnRegisteredLeadDf['academicYear'].replace(to_replace = {r'2020 - 2021' : '2020'},regex=True)\n",
    "normalizedUnRegisteredLeadDf['academicYear'] = normalizedUnRegisteredLeadDf['academicYear'].replace(to_replace = {r'2019 -2020' : '2020'},regex=True)\n",
    "normalizedUnRegisteredLeadDf['academicYear'] = normalizedUnRegisteredLeadDf['academicYear'].replace(to_replace = {r'2013' : '2013'},regex=True)\n",
    "normalizedUnRegisteredLeadDf['academicYear'] = normalizedUnRegisteredLeadDf['academicYear'].replace(to_replace = {r'2020-2021' : '2020'},regex=True)\n",
    "normalizedUnRegisteredLeadDf['academicYear'] = normalizedUnRegisteredLeadDf['academicYear'].replace(to_replace = {r'2019' : '2019'},regex=True)\n",
    "normalizedUnRegisteredLeadDf['academicYear'] = normalizedUnRegisteredLeadDf['academicYear'].replace(to_replace = {r'bcom' : '2020'},regex=True)\n",
    "normalizedUnRegisteredLeadDf['academicYear'] = normalizedUnRegisteredLeadDf['academicYear'].replace(to_replace = {r'2021-22' : '2021'},regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-20    128302\n",
       "2018        56071\n",
       "2020        37002\n",
       "2016          515\n",
       "2021           68\n",
       "2013           10\n",
       "2019            9\n",
       "Name: academicYear, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizedUnRegisteredLeadDf['academicYear'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remarks</th>\n",
       "      <th>leadName</th>\n",
       "      <th>gender</th>\n",
       "      <th>city</th>\n",
       "      <th>reference</th>\n",
       "      <th>notes</th>\n",
       "      <th>academicYear</th>\n",
       "      <th>englishYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>switch off</td>\n",
       "      <td>vinayak sharma</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>nmat -2017</td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>switch off</td>\n",
       "      <td>vinayak sharma</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>nmat -2017</td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>switch off</td>\n",
       "      <td>vinayak sharma</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>nmat -2017</td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>not pick</td>\n",
       "      <td>vinayak sharma</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>nmat -2017</td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>switch off</td>\n",
       "      <td>vinayak sharma</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>nmat -2017</td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221955</th>\n",
       "      <td>not attending//mail/mailer-2</td>\n",
       "      <td>thejesh reddy m</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>website general enquiry</td>\n",
       "      <td>btech</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221956</th>\n",
       "      <td>not attending</td>\n",
       "      <td>thejesh reddy m</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>website general enquiry</td>\n",
       "      <td>btech</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221957</th>\n",
       "      <td>joined in ap colleges</td>\n",
       "      <td>thejesh reddy m</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>website general enquiry</td>\n",
       "      <td>btech</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221958</th>\n",
       "      <td>not attending</td>\n",
       "      <td>thejesh reddy m</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>website general enquiry</td>\n",
       "      <td>btech</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221959</th>\n",
       "      <td>disturbance on call</td>\n",
       "      <td>thejesh reddy m</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>website general enquiry</td>\n",
       "      <td>btech</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56596 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             remarks          leadName gender city  \\\n",
       "141                       switch off    vinayak sharma               \n",
       "142                       switch off    vinayak sharma               \n",
       "143                       switch off    vinayak sharma               \n",
       "144                         not pick    vinayak sharma               \n",
       "145                       switch off    vinayak sharma               \n",
       "...                              ...               ...    ...  ...   \n",
       "221955  not attending//mail/mailer-2   thejesh reddy m               \n",
       "221956                 not attending   thejesh reddy m               \n",
       "221957        joined in ap colleges    thejesh reddy m               \n",
       "221958                 not attending   thejesh reddy m               \n",
       "221959         disturbance on call     thejesh reddy m               \n",
       "\n",
       "                      reference  notes academicYear englishYear  \n",
       "141                  nmat -2017                2016        2019  \n",
       "142                  nmat -2017                2016        2019  \n",
       "143                  nmat -2017                2016        2019  \n",
       "144                  nmat -2017                2016        2019  \n",
       "145                  nmat -2017                2016        2019  \n",
       "...                         ...    ...          ...         ...  \n",
       "221955  website general enquiry  btech         2018        2019  \n",
       "221956  website general enquiry  btech         2018        2019  \n",
       "221957  website general enquiry  btech         2018        2019  \n",
       "221958  website general enquiry  btech         2018        2019  \n",
       "221959  website general enquiry  btech         2018        2019  \n",
       "\n",
       "[56596 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #DataSets Marked as negative response : \n",
    "negDataset1  = normalizedUnRegisteredLeadDf[normalizedUnRegisteredLeadDf['academicYear'].str.contains(\"2016\")]\n",
    "negDataset2  = normalizedUnRegisteredLeadDf[normalizedUnRegisteredLeadDf['academicYear'].str.contains(\"2013\")]\n",
    "negDataset3  = normalizedUnRegisteredLeadDf[normalizedUnRegisteredLeadDf['academicYear'] == '2018']\n",
    "negframes = [negDataset1,negDataset2,negDataset3]\n",
    "negDataset = pd.concat(negframes, sort=False)\n",
    "negDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have taken only leads from previous years, in order to balance the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leadName</th>\n",
       "      <th>remarks</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\takanksha singh</td>\n",
       "      <td>not attending/ sent greeting mails,no mail id/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\takhil c suresh</td>\n",
       "      <td>transferred rs 10000for registration on may 30...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\tanisha annu rary</td>\n",
       "      <td>mat-700.50/ degree- 80 above/ discussinga abou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\tarmaan mukesh</td>\n",
       "      <td>i spoke to arman candidate dad so he is lookin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\tashiq g mithra</td>\n",
       "      <td>waiting for suppli exam given details /transfe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>shrinidhi katti</td>\n",
       "      <td>he is doing his bba 5th semister.told his the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>steffy sebastian</td>\n",
       "      <td>i spoke to her mom and gave all details. as ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>sushmitha s</td>\n",
       "      <td>applied for st.joseph, waiting for the result....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>swamini suryakant gabhane</td>\n",
       "      <td>maharastra 10-94.20 12-74. neet-308 kea reg do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>vidhathri v</td>\n",
       "      <td>switch off or not reachable.,switch off or not...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1596 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        leadName  \\\n",
       "0               \\takanksha singh   \n",
       "1               \\takhil c suresh   \n",
       "2             \\tanisha annu rary   \n",
       "3                \\tarmaan mukesh   \n",
       "4               \\tashiq g mithra   \n",
       "...                          ...   \n",
       "1591             shrinidhi katti   \n",
       "1592            steffy sebastian   \n",
       "1593                 sushmitha s   \n",
       "1594   swamini suryakant gabhane   \n",
       "1595                 vidhathri v   \n",
       "\n",
       "                                                remarks  response  \n",
       "0     not attending/ sent greeting mails,no mail id/...         1  \n",
       "1     transferred rs 10000for registration on may 30...         1  \n",
       "2     mat-700.50/ degree- 80 above/ discussinga abou...         1  \n",
       "3     i spoke to arman candidate dad so he is lookin...         1  \n",
       "4     waiting for suppli exam given details /transfe...         1  \n",
       "...                                                 ...       ...  \n",
       "1591  he is doing his bba 5th semister.told his the ...         1  \n",
       "1592  i spoke to her mom and gave all details. as ca...         1  \n",
       "1593  applied for st.joseph, waiting for the result....         1  \n",
       "1594  maharastra 10-94.20 12-74. neet-308 kea reg do...         1  \n",
       "1595  switch off or not reachable.,switch off or not...         1  \n",
       "\n",
       "[1596 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grouping remarks column for each candidate and creating a training dataset for both positive and negative datasets.\n",
    "#Positive dataset : Response = 1 as in they joined the organisation\n",
    "posCallResponse = normalizedRegisteredLeadDf.groupby('leadName')['remarks'].apply(list).reset_index(name='remarks')\n",
    "posCallResponse['remarks'] = [','.join(map(str, each)) for each in posCallResponse['remarks']]\n",
    "posCallResponse['response'] = 1\n",
    "posCallResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leadName</th>\n",
       "      <th>remarks</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\t\\tanupam narayana</td>\n",
       "      <td>rnr,i directly askd want adm or not but told o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\t\\tgelly nayak</td>\n",
       "      <td>rnr,told lil busy n disconnected ,rnr,told not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\t\\tindranil sen</td>\n",
       "      <td>b tech cs, 10th in between disconnected ,sent...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\t\\tsomyadip mukharjee</td>\n",
       "      <td>took adm in kolkata,still i asked do u want in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\taakash</td>\n",
       "      <td>num is not valid..,num is not valid..,num is n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>vishnu.v</td>\n",
       "      <td>repeated student/contact me,planning to repeat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703</th>\n",
       "      <td>zoramliana</td>\n",
       "      <td>so sent mail and whats app message ,switch off...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>ńîkħíł móħáńtÿ</td>\n",
       "      <td>m busy will call u once free n disconnected th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705</th>\n",
       "      <td>ʍօհժ ƙɑíƒ</td>\n",
       "      <td>looking for admission next year</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4706</th>\n",
       "      <td>чσgєѕhwαri . e</td>\n",
       "      <td>asked to call tomorrow as not available ,dad s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4707 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     leadName  \\\n",
       "0        \\t\\tanupam narayana    \n",
       "1            \\t\\tgelly nayak    \n",
       "2            \\t\\tindranil sen   \n",
       "3     \\t\\tsomyadip mukharjee    \n",
       "4                    \\taakash   \n",
       "...                       ...   \n",
       "4702                 vishnu.v   \n",
       "4703               zoramliana   \n",
       "4704           ńîkħíł móħáńtÿ   \n",
       "4705                ʍօհժ ƙɑíƒ   \n",
       "4706           чσgєѕhwαri . e   \n",
       "\n",
       "                                                remarks  response  \n",
       "0     rnr,i directly askd want adm or not but told o...         0  \n",
       "1     rnr,told lil busy n disconnected ,rnr,told not...         0  \n",
       "2      b tech cs, 10th in between disconnected ,sent...         0  \n",
       "3     took adm in kolkata,still i asked do u want in...         0  \n",
       "4     num is not valid..,num is not valid..,num is n...         0  \n",
       "...                                                 ...       ...  \n",
       "4702  repeated student/contact me,planning to repeat...         0  \n",
       "4703  so sent mail and whats app message ,switch off...         0  \n",
       "4704  m busy will call u once free n disconnected th...         0  \n",
       "4705                   looking for admission next year          0  \n",
       "4706  asked to call tomorrow as not available ,dad s...         0  \n",
       "\n",
       "[4707 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Negative Dataset : Response = 0 as in they refused to join\n",
    "negCallResponse = negDataset.groupby('leadName')['remarks'].apply(list).reset_index(name='remarks')\n",
    "#print(negCallResponse)\n",
    "negCallResponse['remarks'] = [','.join(map(str, each)) for each in negCallResponse['remarks']]\n",
    "negCallResponse['response'] = 0    \n",
    "#negCallResponse.index\n",
    "negCallResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We shall split the training data into 3 parts :  With positive values being 1596 and negative values being 1569 in each training dataset.\n",
    "negTrainingData1 = pd.DataFrame(negCallResponse,index = range(0,1569))\n",
    "negTrainingData2 = pd.DataFrame(negCallResponse,index = range(1569,3138))\n",
    "negTrainingData3 = pd.DataFrame(negCallResponse,index = range(3138,4707))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data1 \n",
    "data1 = [posCallResponse,negTrainingData1]\n",
    "TrainingData1 = pd.concat(data1, sort=False)\n",
    "#TrainingData1 = TrainingData1[['remarks','response']]\n",
    "\n",
    "#Training Data2\n",
    "data2 = [posCallResponse,negTrainingData2]\n",
    "TrainingData2 = pd.concat(data1, sort=False)\n",
    "\n",
    "\n",
    "#Training Data3\n",
    "data3 = [posCallResponse,negTrainingData3]\n",
    "TrainingData3 = pd.concat(data1, sort=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dataset):\n",
    "    callLogs = dataset['remarks']\n",
    "    #use regular expressions to replace email addresses, URLs, phone numbers, other numbers\n",
    "\n",
    "    # Replace email addresses with 'email'\n",
    "    processed = callLogs.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','emailaddress')\n",
    "\n",
    "    # Replace URLs with 'webaddress'\n",
    "    processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'webaddress')\n",
    "\n",
    "    # Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
    "    processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "    \n",
    "    # Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "    processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
    "                                  'phonenumber')\n",
    "    #Replace percentage:\n",
    "    processed = processed.str.replace(r'^[0-9]*\\%', 'percentage')\n",
    "\n",
    "    # Remove punctuation\n",
    "    processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "    # Replace whitespace between terms with a single space\n",
    "    processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "    # Remove leading and trailing whitespace\n",
    "    processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "    \n",
    "    return processed\n",
    "\n",
    "processedTrainingData1 = process_data(TrainingData1)\n",
    "processedTrainingData2 = process_data(TrainingData2)\n",
    "processedTrainingData3 = process_data(TrainingData3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(processedTrainingData):\n",
    "    corpus = []\n",
    "    for i in range(len(processedTrainingData)):\n",
    "        review = processedTrainingData.iloc[i]\n",
    "        review = review.split()\n",
    "        ps = PorterStemmer()\n",
    "        all_stopwords = stopwords.words('english')\n",
    "        all_stopwords.remove('not')\n",
    "        review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "    return corpus\n",
    "cleanedTrainingData1 = clean_data(processedTrainingData1)\n",
    "cleanedTrainingData2 = clean_data(processedTrainingData2)\n",
    "cleanedTrainingData3 = clean_data(processedTrainingData3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_model(corpus,dataset):\n",
    "    cv = CountVectorizer(max_features=1500)\n",
    "    X = cv.fit_transform(corpus).toarray()\n",
    "    y = dataset.iloc[:, -1].values\n",
    "    return X,y\n",
    "\n",
    "logs1,classes1 = bag_of_words_model(cleanedTrainingData1,TrainingData1)\n",
    "logs2,classes2 = bag_of_words_model(cleanedTrainingData2,TrainingData2)\n",
    "logs3,classes3 = bag_of_words_model(cleanedTrainingData3,TrainingData3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_the_dataset(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 96)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "X_train1, X_test1, y_train1, y_test1 = split_the_dataset(logs1,classes1)\n",
    "X_train2, X_test2, y_train2, y_test2 = split_the_dataset(logs2,classes2)\n",
    "X_train3, X_test3, y_train3, y_test3 = split_the_dataset(logs3,classes3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calBestRandomStateOf(model,X,y):\n",
    "    max_score=0\n",
    "    for i in range(40,100):\n",
    "        x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=.20,random_state=i)\n",
    "        model.fit(x_train,y_train)\n",
    "        pred = model.predict(x_test)\n",
    "        score = accuracy_score(y_test,pred)\n",
    "        if score>max_score:\n",
    "            max_score = score\n",
    "            final_state = i\n",
    "\n",
    "    return final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def build_models(X_train,X_test,y_train,y_test):\n",
    "    # Define models to train\n",
    "    names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "    classifiers = [\n",
    "        KNeighborsClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        LogisticRegression(),\n",
    "        SGDClassifier(),\n",
    "        MultinomialNB(),\n",
    "        SVC()\n",
    "    ]\n",
    "\n",
    "    models = zip(names, classifiers)\n",
    "\n",
    "    for name, model in models:\n",
    "        classifier = model\n",
    "        training_data = classifier.fit(X_train,y_train)\n",
    "        y_pred = training_data.predict(X_test)\n",
    "        print(\"Classifier :\", name)\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        confusionmatrix = confusion_matrix(y_test, y_pred)\n",
    "        print(\" Confusion Matrix :\")\n",
    "        print(confusionmatrix)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(\"Accuracy : \",accuracy*100)\n",
    "        classificationreport = classification_report(y_test, y_pred)\n",
    "        print(\"Classification Report : \")\n",
    "        print(classificationreport)\n",
    "        print(\"--------------------------------------------------------\")\n",
    "        \n",
    "    \n",
    "        cv_score = cross_val_score(classifier,X_train,y_train,cv=5,scoring='accuracy')\n",
    "        print(\"*************************************************************************************\")\n",
    "        print(\"Cross Validatiob Score for \",classifier,\" : \")\n",
    "        print(\"Score : \", cv_score)\n",
    "        print(\"Mean : \", cv_score.mean())\n",
    "        print(\"Standard Deviation : \", cv_score.std())\n",
    "        print(\"*************************************************************************************\")\n",
    "        print(\"\")\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier : K Nearest Neighbors\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[297  14]\n",
      " [125 197]]\n",
      "Accuracy :  78.04107424960506\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.95      0.81       311\n",
      "           1       0.93      0.61      0.74       322\n",
      "\n",
      "    accuracy                           0.78       633\n",
      "   macro avg       0.82      0.78      0.77       633\n",
      "weighted avg       0.82      0.78      0.77       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  KNeighborsClassifier()  : \n",
      "Score :  [0.78500986 0.80473373 0.78656126 0.8201581  0.79249012]\n",
      "Mean :  0.7977906151819195\n",
      "Standard Deviation :  0.013160946327730887\n",
      "*************************************************************************************\n",
      "\n",
      "Classifier : Decision Tree\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[265  46]\n",
      " [ 45 277]]\n",
      "Accuracy :  85.62401263823065\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       311\n",
      "           1       0.86      0.86      0.86       322\n",
      "\n",
      "    accuracy                           0.86       633\n",
      "   macro avg       0.86      0.86      0.86       633\n",
      "weighted avg       0.86      0.86      0.86       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  DecisionTreeClassifier()  : \n",
      "Score :  [0.81854043 0.85404339 0.85375494 0.84980237 0.84782609]\n",
      "Mean :  0.8447934451278932\n",
      "Standard Deviation :  0.013336992067678848\n",
      "*************************************************************************************\n",
      "\n",
      "Classifier : Random Forest\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[285  26]\n",
      " [ 18 304]]\n",
      "Accuracy :  93.04897314375987\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       311\n",
      "           1       0.92      0.94      0.93       322\n",
      "\n",
      "    accuracy                           0.93       633\n",
      "   macro avg       0.93      0.93      0.93       633\n",
      "weighted avg       0.93      0.93      0.93       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  RandomForestClassifier()  : \n",
      "Score :  [0.89546351 0.92899408 0.9229249  0.93873518 0.93873518]\n",
      "Mean :  0.9249705701210719\n",
      "Standard Deviation :  0.015937181781315087\n",
      "*************************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier : Logistic Regression\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[291  20]\n",
      " [ 36 286]]\n",
      "Accuracy :  91.15323854660348\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       311\n",
      "           1       0.93      0.89      0.91       322\n",
      "\n",
      "    accuracy                           0.91       633\n",
      "   macro avg       0.91      0.91      0.91       633\n",
      "weighted avg       0.91      0.91      0.91       633\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************\n",
      "Cross Validatiob Score for  LogisticRegression()  : \n",
      "Score :  [0.89940828 0.92504931 0.91699605 0.9229249  0.92094862]\n",
      "Mean :  0.9170654317811507\n",
      "Standard Deviation :  0.009218833909167872\n",
      "*************************************************************************************\n",
      "\n",
      "Classifier : SGD Classifier\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[265  46]\n",
      " [ 28 294]]\n",
      "Accuracy :  88.30963665086888\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88       311\n",
      "           1       0.86      0.91      0.89       322\n",
      "\n",
      "    accuracy                           0.88       633\n",
      "   macro avg       0.88      0.88      0.88       633\n",
      "weighted avg       0.88      0.88      0.88       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  SGDClassifier()  : \n",
      "Score :  [0.89940828 0.91321499 0.90316206 0.88142292 0.90513834]\n",
      "Mean :  0.9004693188639676\n",
      "Standard Deviation :  0.010539389370199766\n",
      "*************************************************************************************\n",
      "\n",
      "Classifier : Naive Bayes\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[283  28]\n",
      " [ 51 271]]\n",
      "Accuracy :  87.51974723538704\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       311\n",
      "           1       0.91      0.84      0.87       322\n",
      "\n",
      "    accuracy                           0.88       633\n",
      "   macro avg       0.88      0.88      0.88       633\n",
      "weighted avg       0.88      0.88      0.88       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  MultinomialNB()  : \n",
      "Score :  [0.87376726 0.89349112 0.89525692 0.87747036 0.88537549]\n",
      "Mean :  0.8850722298882834\n",
      "Standard Deviation :  0.008488680398493645\n",
      "*************************************************************************************\n",
      "\n",
      "Classifier : SVM Linear\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[298  13]\n",
      " [ 57 265]]\n",
      "Accuracy :  88.94154818325435\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89       311\n",
      "           1       0.95      0.82      0.88       322\n",
      "\n",
      "    accuracy                           0.89       633\n",
      "   macro avg       0.90      0.89      0.89       633\n",
      "weighted avg       0.90      0.89      0.89       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  SVC()  : \n",
      "Score :  [0.89940828 0.90927022 0.90118577 0.89920949 0.90118577]\n",
      "Mean :  0.9020519057308356\n",
      "Standard Deviation :  0.0037060081315959895\n",
      "*************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_models(X_train1, X_test1, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier : K Nearest Neighbors\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[297  14]\n",
      " [125 197]]\n",
      "Accuracy :  78.04107424960506\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.95      0.81       311\n",
      "           1       0.93      0.61      0.74       322\n",
      "\n",
      "    accuracy                           0.78       633\n",
      "   macro avg       0.82      0.78      0.77       633\n",
      "weighted avg       0.82      0.78      0.77       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  KNeighborsClassifier()  : \n",
      "Score :  [0.78500986 0.80473373 0.78656126 0.8201581  0.79249012]\n",
      "Mean :  0.7977906151819195\n",
      "Standard Deviation :  0.013160946327730887\n",
      "*************************************************************************************\n",
      "\n",
      "Classifier : Decision Tree\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[268  43]\n",
      " [ 47 275]]\n",
      "Accuracy :  85.78199052132702\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86       311\n",
      "           1       0.86      0.85      0.86       322\n",
      "\n",
      "    accuracy                           0.86       633\n",
      "   macro avg       0.86      0.86      0.86       633\n",
      "weighted avg       0.86      0.86      0.86       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  DecisionTreeClassifier()  : \n",
      "Score :  [0.80670611 0.87573964 0.85573123 0.83596838 0.84980237]\n",
      "Mean :  0.8447895471306843\n",
      "Standard Deviation :  0.022938692787202758\n",
      "*************************************************************************************\n",
      "\n",
      "Classifier : Random Forest\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[287  24]\n",
      " [ 19 303]]\n",
      "Accuracy :  93.20695102685625\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       311\n",
      "           1       0.93      0.94      0.93       322\n",
      "\n",
      "    accuracy                           0.93       633\n",
      "   macro avg       0.93      0.93      0.93       633\n",
      "weighted avg       0.93      0.93      0.93       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  RandomForestClassifier()  : \n",
      "Score :  [0.89349112 0.93688363 0.92687747 0.94268775 0.92490119]\n",
      "Mean :  0.9249682313227463\n",
      "Standard Deviation :  0.017031828447186287\n",
      "*************************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier : Logistic Regression\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[291  20]\n",
      " [ 36 286]]\n",
      "Accuracy :  91.15323854660348\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       311\n",
      "           1       0.93      0.89      0.91       322\n",
      "\n",
      "    accuracy                           0.91       633\n",
      "   macro avg       0.91      0.91      0.91       633\n",
      "weighted avg       0.91      0.91      0.91       633\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************\n",
      "Cross Validatiob Score for  LogisticRegression()  : \n",
      "Score :  [0.89940828 0.92504931 0.91699605 0.9229249  0.92094862]\n",
      "Mean :  0.9170654317811507\n",
      "Standard Deviation :  0.009218833909167872\n",
      "*************************************************************************************\n",
      "\n",
      "Classifier : SGD Classifier\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[285  26]\n",
      " [ 42 280]]\n",
      "Accuracy :  89.25750394944708\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       311\n",
      "           1       0.92      0.87      0.89       322\n",
      "\n",
      "    accuracy                           0.89       633\n",
      "   macro avg       0.89      0.89      0.89       633\n",
      "weighted avg       0.89      0.89      0.89       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  SGDClassifier()  : \n",
      "Score :  [0.89349112 0.90729783 0.72332016 0.91501976 0.90711462]\n",
      "Mean :  0.8692487000179308\n",
      "Standard Deviation :  0.0732930954855558\n",
      "*************************************************************************************\n",
      "\n",
      "Classifier : Naive Bayes\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[283  28]\n",
      " [ 51 271]]\n",
      "Accuracy :  87.51974723538704\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       311\n",
      "           1       0.91      0.84      0.87       322\n",
      "\n",
      "    accuracy                           0.88       633\n",
      "   macro avg       0.88      0.88      0.88       633\n",
      "weighted avg       0.88      0.88      0.88       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  MultinomialNB()  : \n",
      "Score :  [0.87376726 0.89349112 0.89525692 0.87747036 0.88537549]\n",
      "Mean :  0.8850722298882834\n",
      "Standard Deviation :  0.008488680398493645\n",
      "*************************************************************************************\n",
      "\n",
      "Classifier : SVM Linear\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[298  13]\n",
      " [ 57 265]]\n",
      "Accuracy :  88.94154818325435\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89       311\n",
      "           1       0.95      0.82      0.88       322\n",
      "\n",
      "    accuracy                           0.89       633\n",
      "   macro avg       0.90      0.89      0.89       633\n",
      "weighted avg       0.90      0.89      0.89       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  SVC()  : \n",
      "Score :  [0.89940828 0.90927022 0.90118577 0.89920949 0.90118577]\n",
      "Mean :  0.9020519057308356\n",
      "Standard Deviation :  0.0037060081315959895\n",
      "*************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_models(X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier : K Nearest Neighbors\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[297  14]\n",
      " [125 197]]\n",
      "Accuracy :  78.04107424960506\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.95      0.81       311\n",
      "           1       0.93      0.61      0.74       322\n",
      "\n",
      "    accuracy                           0.78       633\n",
      "   macro avg       0.82      0.78      0.77       633\n",
      "weighted avg       0.82      0.78      0.77       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  KNeighborsClassifier()  : \n",
      "Score :  [0.78500986 0.80473373 0.78656126 0.8201581  0.79249012]\n",
      "Mean :  0.7977906151819195\n",
      "Standard Deviation :  0.013160946327730887\n",
      "*************************************************************************************\n",
      "\n",
      "Classifier : Decision Tree\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[260  51]\n",
      " [ 55 267]]\n",
      "Accuracy :  83.25434439178515\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83       311\n",
      "           1       0.84      0.83      0.83       322\n",
      "\n",
      "    accuracy                           0.83       633\n",
      "   macro avg       0.83      0.83      0.83       633\n",
      "weighted avg       0.83      0.83      0.83       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  DecisionTreeClassifier()  : \n",
      "Score :  [0.80473373 0.85404339 0.85177866 0.84980237 0.84980237]\n",
      "Mean :  0.8420321039050137\n",
      "Standard Deviation :  0.01871464299204323\n",
      "*************************************************************************************\n",
      "\n",
      "Classifier : Random Forest\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[288  23]\n",
      " [ 19 303]]\n",
      "Accuracy :  93.36492890995261\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       311\n",
      "           1       0.93      0.94      0.94       322\n",
      "\n",
      "    accuracy                           0.93       633\n",
      "   macro avg       0.93      0.93      0.93       633\n",
      "weighted avg       0.93      0.93      0.93       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  RandomForestClassifier()  : \n",
      "Score :  [0.90138067 0.93293886 0.92885375 0.93478261 0.94268775]\n",
      "Mean :  0.9281287274598311\n",
      "Standard Deviation :  0.014109292918107537\n",
      "*************************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier : Logistic Regression\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[291  20]\n",
      " [ 36 286]]\n",
      "Accuracy :  91.15323854660348\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       311\n",
      "           1       0.93      0.89      0.91       322\n",
      "\n",
      "    accuracy                           0.91       633\n",
      "   macro avg       0.91      0.91      0.91       633\n",
      "weighted avg       0.91      0.91      0.91       633\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sbhatt\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************\n",
      "Cross Validatiob Score for  LogisticRegression()  : \n",
      "Score :  [0.89940828 0.92504931 0.91699605 0.9229249  0.92094862]\n",
      "Mean :  0.9170654317811507\n",
      "Standard Deviation :  0.009218833909167872\n",
      "*************************************************************************************\n",
      "\n",
      "Classifier : SGD Classifier\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[288  23]\n",
      " [ 40 282]]\n",
      "Accuracy :  90.04739336492891\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90       311\n",
      "           1       0.92      0.88      0.90       322\n",
      "\n",
      "    accuracy                           0.90       633\n",
      "   macro avg       0.90      0.90      0.90       633\n",
      "weighted avg       0.90      0.90      0.90       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  SGDClassifier()  : \n",
      "Score :  [0.86193294 0.91715976 0.8972332  0.92687747 0.8972332 ]\n",
      "Mean :  0.9000873151374822\n",
      "Standard Deviation :  0.022276576313062253\n",
      "*************************************************************************************\n",
      "\n",
      "Classifier : Naive Bayes\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[283  28]\n",
      " [ 51 271]]\n",
      "Accuracy :  87.51974723538704\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       311\n",
      "           1       0.91      0.84      0.87       322\n",
      "\n",
      "    accuracy                           0.88       633\n",
      "   macro avg       0.88      0.88      0.88       633\n",
      "weighted avg       0.88      0.88      0.88       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  MultinomialNB()  : \n",
      "Score :  [0.87376726 0.89349112 0.89525692 0.87747036 0.88537549]\n",
      "Mean :  0.8850722298882834\n",
      "Standard Deviation :  0.008488680398493645\n",
      "*************************************************************************************\n",
      "\n",
      "Classifier : SVM Linear\n",
      "-----------------------------------------------------\n",
      " Confusion Matrix :\n",
      "[[298  13]\n",
      " [ 57 265]]\n",
      "Accuracy :  88.94154818325435\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89       311\n",
      "           1       0.95      0.82      0.88       322\n",
      "\n",
      "    accuracy                           0.89       633\n",
      "   macro avg       0.90      0.89      0.89       633\n",
      "weighted avg       0.90      0.89      0.89       633\n",
      "\n",
      "--------------------------------------------------------\n",
      "*************************************************************************************\n",
      "Cross Validatiob Score for  SVC()  : \n",
      "Score :  [0.89940828 0.90927022 0.90118577 0.89920949 0.90118577]\n",
      "Mean :  0.9020519057308356\n",
      "Standard Deviation :  0.0037060081315959895\n",
      "*************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_models(X_train3, X_test3, y_train3, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations : \n",
    "    1. From the above results, we can see that Random forest algorithm performs better than the rest of the model on second dataset.\n",
    "    2. Random Forest Algorithm is giving out results with 93.13%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-7720cd59973e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mgridsearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mgridsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mgridsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Final Model :\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "  \n",
    "random_search = {'criterion': ['entropy', 'gini'],\n",
    "               'max_features': ['auto', 'sqrt','log2', None],\n",
    "               'min_samples_leaf': [4, 6, 8, 12],\n",
    "               'min_samples_split': [5, 7, 10, 14]\n",
    "                }\n",
    "\n",
    "gridsearch = GridSearchCV(RandomForestClassifier(),random_search,n_jobs=-1,pre_dispatch=2)\n",
    "gridsearch.fit(logs2,classes2)\n",
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicting_data = normalizedUnRegisteredLeadDf.groupby('leadName')['remarks'].apply(list).reset_index(name='remarks')\n",
    "predicting_data['remarks'] = [','.join(map(str, each)) for each in predicting_data['remarks']]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = process_data(predicting_data)\n",
    "clean = clean_data(process)\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(clean).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(max_iter = 200)\n",
    "fitting = classifier.fit(X_train2,y_train2)\n",
    "final_pred = fitting.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(final_pred)\n",
    "output.shape\n",
    "predicting_data['predictedValue'] = output\n",
    "final_output = predicting_data[['leadName','predictedValue']]\n",
    "\n",
    "final_output['leadName'] = final_output['leadName'].replace(to_replace = {r'^\\t*' : ''},regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = unregisteredLeadDf.merge(final_output, on='leadName',how='right')\n",
    "final[final['predictedValue'] == 1][:10]\n",
    "final.to_excel(r'C:\\\\Users\\sbhatt\\Documents\\Python Scripts\\Datasets\\Lead Analysis\\\\leads.xlsx', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
